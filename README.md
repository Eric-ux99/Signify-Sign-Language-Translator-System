# Signify: Real-Time Sign Language Detection System

Signify is a desktop-based application designed to bridge communication gaps between mute and hearing communities. It uses computer vision and deep learning to detect and translate sign language gestures into readable text in real time.

## ğŸ§  Motivation

Despite technological advancements, mute individuals still face barriers in social, educational, and professional settings. Signify aims to provide an inclusive solution by enabling seamless communication through gesture recognition.

## ğŸš€ Features

- Real-time gesture detection using webcam input
- Custom gesture training for vocabulary expansion
- PyQt-based user interface for intuitive interaction
- Continuous learning to improve recognition accuracy
- Compatibility with standard desktop environments

## ğŸ› ï¸ Tech Stack

- **Programming Language:** Python
- **Libraries & Frameworks:** OpenCV, MediaPipe, TensorFlow/Keras, PyQt
- **Tools:** Google Teachable Machine, NumPy

## ğŸ“Š System Architecture
The system consists of:
- Gesture Detection Module (MediaPipe + OpenCV)
- Prediction Engine (TensorFlow/Keras)
- User Interface (PyQt)
- Training Module (Teachable Machine integration)
